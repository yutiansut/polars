<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>pypolars.frame API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pypolars.frame</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">try:
    from .pypolars import PyDataFrame, PySeries, PyLazyFrame
except:
    import warnings

    warnings.warn(&#34;binary files missing&#34;)
    __pdoc__ = {&#34;wrap_df&#34;: False}

from typing import (
    Dict,
    Sequence,
    List,
    Tuple,
    Optional,
    Union,
    TextIO,
    BinaryIO,
    Callable,
    Any,
)
from .series import Series, wrap_s
from .datatypes import *
import numpy as np


def wrap_df(df: &#34;PyDataFrame&#34;) -&gt; &#34;DataFrame&#34;:
    return DataFrame._from_pydf(df)


def prepare_other(other: Any) -&gt; Series:
    # if not a series create singleton series such that it will broadcast
    if not isinstance(other, Series):
        if isinstance(other, str):
            pass
        elif isinstance(other, Sequence):
            raise ValueError(&#34;operation not supported&#34;)

        other = Series(&#34;&#34;, [other])
    return other


class DataFrame:
    def __init__(self, data: Dict[str, Sequence], nullable: bool = False):

        columns = []
        if isinstance(data, dict):
            for k, v in data.items():
                columns.append(Series(k, v, nullable=nullable).inner())
        elif isinstance(data, list):
            for s in data:
                if not isinstance(s, Series):
                    raise ValueError(&#34;a list should contain Series&#34;)
                columns.append(s.inner())
        else:
            try:
                import pandas as pd

                if isinstance(data, pd.DataFrame):
                    for c in data.columns:
                        if nullable:
                            s = Series(c, data[c].to_list(), nullable=True).inner()
                        else:
                            s = Series(c, data[c].values, nullable=False).inner()
                        columns.append(s)
                else:
                    raise ValueError(&#34;a dictionary was expected.&#34;)
            except ImportError:
                raise ValueError(&#34;a dictionary was expected.&#34;)

        self._df = PyDataFrame(columns)

    @staticmethod
    def _from_pydf(df: &#34;PyDataFrame&#34;) -&gt; &#34;DataFrame&#34;:
        self = DataFrame.__new__(DataFrame)
        self._df = df
        return self

    @staticmethod
    def read_csv(
        file: Union[str, TextIO],
        infer_schema_length: int = 100,
        batch_size: int = 1000,
        has_headers: bool = True,
        ignore_errors: bool = False,
        stop_after_n_rows: Optional[int] = None,
        skip_rows: int = 0,
        projection: &#34;Optional[List[int]]&#34; = None,
        sep: str = &#34;,&#34;,
        columns: &#34;Optional[List[str]]&#34; = None,
        rechunk: bool = True,
        encoding: str = &#34;utf8&#34;,
        one_thread: bool = True,
    ) -&gt; &#34;DataFrame&#34;:
        self = DataFrame.__new__(DataFrame)
        self._df = PyDataFrame.read_csv(
            file,
            infer_schema_length,
            batch_size,
            has_headers,
            ignore_errors,
            stop_after_n_rows,
            skip_rows,
            projection,
            sep,
            rechunk,
            columns,
            encoding,
            one_thread,
        )
        return self

    @staticmethod
    def read_parquet(
        file: Union[str, BinaryIO],
    ) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Read into a DataFrame from a parquet file.

        Parameters
        ----------
        file
            Path to a file or a file like object.

        Returns
        -------
        DataFrame
        &#34;&#34;&#34;
        self = DataFrame.__new__(DataFrame)
        self._df = PyDataFrame.read_parquet(file)
        return self

    @staticmethod
    def read_ipc(file: Union[str, BinaryIO]) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Read into a DataFrame from Arrow IPC stream format. This is also called the feather format.

        Parameters
        ----------
        file
            Path to a file or a file like object.

        Returns
        -------
        DataFrame
        &#34;&#34;&#34;
        self = DataFrame.__new__(DataFrame)
        self._df = PyDataFrame.read_ipc(file)
        return self

    def to_pandas(self) -&gt; &#34;pd.DataFrame&#34;:
        &#34;&#34;&#34;
        cast to a Pandas DataFrame.
        &#34;&#34;&#34;
        import pandas as pd

        data = {}
        for col in self.columns:
            series = self[col]
            if series.dtype == List:
                data[col] = series.to_list()
            elif series.dtype == Utf8:
                data[col] = series.to_list()
            else:
                data[col] = series.to_numpy()
        return pd.DataFrame(data)

    def to_csv(
        self,
        file: Union[TextIO, str],
        batch_size: int = 100000,
        has_headers: bool = True,
        delimiter: str = &#34;,&#34;,
    ):
        &#34;&#34;&#34;
        Write DataFrame to CSV

        Parameters
        ----------
        file
            write location
        batch_size
            Size of the write buffer. Increase to have faster io.
        has_headers
            Whether or not to include header in the CSV output.
        delimiter
            Space elements with this symbol.
        &#34;&#34;&#34;
        self._df.to_csv(file, batch_size, has_headers, ord(delimiter))

    def to_ipc(self, file: Union[BinaryIO, str], batch_size):
        &#34;&#34;&#34;
        Write to Arrow IPC binary stream, or a feather file.

        Parameters
        ----------
        file
            write location
        batch_size
            Size of the write buffer. Increase to have faster io.
        &#34;&#34;&#34;
        self._df.to_ipc(file, batch_size)

    def to_numpy(self) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Convert DataFrame to a 2d numpy array.
        This operation clones data.
        &#34;&#34;&#34;
        return np.vstack([self[:, i].to_numpy() for i in range(self.width)]).T

    def __mul__(self, other):
        other = prepare_other(other)
        return wrap_df(self._df.mul(other._s))

    def __truediv__(self, other):
        other = prepare_other(other)
        return wrap_df(self._df.div(other._s))

    def __add__(self, other):
        other = prepare_other(other)
        return wrap_df(self._df.add(other._s))

    def __sub__(self, other):
        other = prepare_other(other)
        return wrap_df(self._df.sub(other._s))

    def __str__(self) -&gt; str:
        return self._df.as_str()

    def __repr__(self) -&gt; str:
        return self.__str__()

    def __getattr__(self, item) -&gt; &#34;PySeries&#34;:
        &#34;&#34;&#34;
        Access columns as attribute
        &#34;&#34;&#34;
        try:
            return wrap_s(self._df.column(item))
        except RuntimeError:
            raise AttributeError(f&#34;{item} not found&#34;)

    def __iter__(self):
        return self.get_columns().__iter__()

    def __getitem__(self, item):
        # select rows and columns at once
        # every 2d selection, i.e. tuple is row column order, just like numpy
        if isinstance(item, tuple):
            row_selection, col_selection = item

            # df[:, unknown]
            if isinstance(row_selection, slice):

                # multiple slices
                # df[:, :]
                if isinstance(col_selection, slice):
                    # TODO: select by indexes as column names can be duplicates
                    df = self.__getitem__(self.columns[col_selection])
                    return df[row_selection]

                # single slice
                # df[:, unknown]
                series = self.__getitem__(col_selection)
                # s[:]
                wrap_s(series[row_selection])

            # column selection can be &#34;a&#34; and [&#34;a&#34;, &#34;b&#34;]
            if isinstance(col_selection, str):
                col_selection = [col_selection]
            df = self.__getitem__(col_selection)
            return df.__getitem__(row_selection)

        # select single column
        # df[&#34;foo&#34;]
        if isinstance(item, str):
            return wrap_s(self._df.column(item))

        # df[idx]
        if isinstance(item, int):
            return wrap_s(self._df.select_at_idx(item))

        # df[:]
        if isinstance(item, slice):
            if getattr(item, &#34;end&#34;, False):
                raise ValueError(&#34;a slice with steps larger than 1 is not supported&#34;)
            if item.start is None:
                start = 0
            else:
                start = item.start
            if item.stop is None:
                stop = self.height
            else:
                stop = item.stop
            length = stop - start
            return self.slice(start, length)

        # select multiple columns
        # df[&#34;foo&#34;, &#34;bar&#34;]
        if isinstance(item, Sequence) and isinstance(item[0], str):
            return wrap_df(self._df.select(item))

        # select rows by mask or index
        # df[[1, 2, 3]]
        # df[true, false, true]
        if isinstance(item, np.ndarray):
            if item.dtype == int:
                return wrap_df(self._df.take(item))
        if isinstance(item, (Series, Sequence)):
            if isinstance(item, Sequence):
                # only bool or integers allowed
                if type(item[0]) == bool:
                    item = Series(&#34;&#34;, item)
                else:
                    return wrap_df(self._df.take(item))
            dtype = item.dtype
            if dtype == Boolean:
                return wrap_df(self._df.filter(item.inner()))
            if dtype == UInt32:
                return wrap_df(self._df.take_with_series(item.inner()))

    def __setitem__(self, key, value):
        # df[&#34;foo&#34;] = series
        if isinstance(key, str):
            try:
                self.drop_in_place(key)
            except:
                pass
            self.hstack([Series(key, value)], in_place=True)
        # df[idx] = series
        elif isinstance(key, int):
            assert isinstance(value, Series)
            self.replace_at_idx(key, value)
        # df[a, b]
        elif isinstance(key, tuple):
            row_selection, col_selection = key
            # get series column selection
            s = self.__getitem__(col_selection)

            # dispatch to __setitem__ of Series to do modification
            s[row_selection] = value

            # now find the location to place series
            # df[idx]
            if isinstance(col_selection, int):
                self.replace_at_idx(0, s)
            # df[&#34;foo&#34;]
            elif isinstance(col_selection, str):
                self.replace(col_selection, s)
        else:
            return NotImplemented

    def __len__(self):
        return self.height

    def insert_at_idx(self, index: int, series: Series):
        self._df.insert_at_idx(index, series._s)

    @property
    def shape(self) -&gt; Tuple[int, int]:
        &#34;&#34;&#34;
        Get shape of the DataFrame
        &#34;&#34;&#34;
        return self._df.shape()

    @property
    def height(self) -&gt; int:
        &#34;&#34;&#34;
        Get height of the DataFrame
        &#34;&#34;&#34;
        return self._df.height()

    @property
    def width(self) -&gt; int:
        &#34;&#34;&#34;
        Get width of the DataFrame
        &#34;&#34;&#34;
        return self._df.width()

    @property
    def columns(self) -&gt; &#34;List[str]&#34;:
        &#34;&#34;&#34;
        get column names
        &#34;&#34;&#34;
        return self._df.columns()

    @columns.setter
    def columns(self, columns: &#34;List[str]&#34;):
        self._df.set_column_names(columns)

    @property
    def dtypes(self) -&gt; &#34;List[type]&#34;:
        &#34;&#34;&#34;
        get dtypes
        &#34;&#34;&#34;
        return [dtypes[idx] for idx in self._df.dtypes()]

    def replace_at_idx(self, index: int, series: Series):
        &#34;&#34;&#34;
        Replace a column at an index  location.

        Parameters
        ----------
        index
            Column index
        series
            Series that will replace the column
        &#34;&#34;&#34;
        self._df.replace_at_idx(index, series._s)

    def sort(
        self, by_column: str, in_place: bool = False, reverse: bool = False
    ) -&gt; Optional[&#34;DataFrame&#34;]:
        &#34;&#34;&#34;
        Sort the DataFrame by column

        Parameters
        ----------
        by_column
            by which column to sort
        in_place
            sort in place or return a sorted DataFrame
        reverse
            reverse sort
        &#34;&#34;&#34;
        if in_place:
            self._df.sort_in_place(by_column, reverse)
        else:
            return wrap_df(self._df.sort(by_column, reverse))

    def frame_equal(self, other: &#34;DataFrame&#34;, null_equal: bool = False) -&gt; bool:
        &#34;&#34;&#34;
        Check if DataFrame is equal to other.

        Parameters
        ----------
        other
            DataFrame to compare with.
        null_equal
            Consider null values as equal.
        &#34;&#34;&#34;
        return self._df.frame_equal(other._df, null_equal)

    def replace(self, column: str, new_col: Series):
        &#34;&#34;&#34;
        Replace a column by a new Series.

        Parameters
        ----------
        column
            Column to replace.
        new_col
            New column to insert.
        &#34;&#34;&#34;
        self._df.replace(column, new_col.inner())

    def slice(self, offset: int, length: int) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Slice this DataFrame over the rows direction.

        Parameters
        ----------
        offset
            Offset index.
        length
            Length of the slice.
        &#34;&#34;&#34;
        return wrap_df(self._df.slice(offset, length))

    def head(self, length: int = 5) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Get first N rows as DataFrame

        Parameters
        ----------
        length
            Length of the head
        &#34;&#34;&#34;
        return wrap_df(self._df.head(length))

    def tail(self, length: int = 5) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Get last N rows as DataFrame

        Parameters
        ----------
        length
            Length of the tail
        &#34;&#34;&#34;
        return wrap_df(self._df.tail(length))

    def drop_nulls(self, subset: &#34;Optional[List[str]]&#34;) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Return a new DataFrame where the null values are dropped
        &#34;&#34;&#34;
        if subset is not None and isinstance(subset, str):
            subset = [subset]
        return wrap_df(self._df.drop_nulls(subset))

    def pipe(self, func: Callable, *args, **kwargs):
        &#34;&#34;&#34;
        Apply a function on Self

        Parameters
        ----------
        func
            Callable
        args
            Arguments
        kwargs
            Keyword arguments
        &#34;&#34;&#34;
        return func(self, *args, **kwargs)

    def groupby(self, by: &#34;Union[str, List[str]]&#34;) -&gt; &#34;GroupBy&#34;:
        &#34;&#34;&#34;
        Start a groupby operation

        Parameters
        ----------
        by
            Column(s) to group by.
        &#34;&#34;&#34;
        if isinstance(by, str):
            by = [by]
        return GroupBy(self._df, by)

    def join(
        self,
        df: &#34;DataFrame&#34;,
        left_on: str,
        right_on: str,
        how=&#34;inner&#34;,
    ) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        SQL like joins

        Parameters
        ----------
        df
            DataFrame to join with
        left_on
            Name of the left join column
        right_on
            Name of the right join column
        how
            Join strategy
                - &#34;inner&#34;
                - &#34;left&#34;
                - &#34;outer&#34;

        Returns
        -------
            Joined DataFrame
        &#34;&#34;&#34;
        try:
            if how == &#34;inner&#34;:
                inner = self._df.inner_join(df._df, left_on, right_on)
            elif how == &#34;left&#34;:
                inner = self._df.left_join(df._df, left_on, right_on)
            elif how == &#34;outer&#34;:
                inner = self._df.outer_join(df._df, left_on, right_on)
            else:
                return NotImplemented
        except Exception as e:
            self._df.with_parallel(False)
            raise e
        return wrap_df(inner)

    def hstack(
        self, columns: &#34;Union[List[Series], DataFrame]&#34;, in_place=False
    ) -&gt; Optional[&#34;DataFrame&#34;]:
        &#34;&#34;&#34;
        Return a new DataFrame grown horizontally by stacking Series to it.

        Parameters
        ----------
        columns
            Series to stack
        in_place
            Modify in place
        &#34;&#34;&#34;
        if not isinstance(columns, list):
            columns = columns.get_columns()
        if in_place:
            self._df.hstack_mut([s.inner() for s in columns])
        else:
            return wrap_df(self._df.hstack([s.inner() for s in columns]))

    def vstack(self, df: &#34;DataFrame&#34;):
        &#34;&#34;&#34;
        Grow this DataFrame vertically by stacking a DataFrame to it.

        Parameters
        ----------
        df
            DataFrame to stack
        &#34;&#34;&#34;
        self._df.vstack(df._df)

    def drop(self, name: str) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Remove column from DataFrame and return as new.

        Parameters
        ----------
        name
            Column to drop
        &#34;&#34;&#34;
        return wrap_df(self._df.drop(name))

    def drop_in_place(self, name: str) -&gt; Series:
        &#34;&#34;&#34;
        Drop in place

        Parameters
        ----------
        name
            Column to drop
        &#34;&#34;&#34;
        return wrap_s(self._df.drop_in_place(name))

    def select_at_idx(self, idx: int) -&gt; Series:
        &#34;&#34;&#34;
        Select column at index location.

        Parameters
        ----------
        idx
            Location of selection
        &#34;&#34;&#34;
        return wrap_s(self._df.select_at_idx(idx))

    def clone(self) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Very cheap deep clone
        &#34;&#34;&#34;
        return wrap_df(self._df.clone())

    def get_columns(self) -&gt; &#34;List[Series]&#34;:
        &#34;&#34;&#34;
        Get the DataFrame as a List of Series
        &#34;&#34;&#34;
        return list(map(lambda s: wrap_s(s), self._df.get_columns()))

    def fill_none(self, strategy: str) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Fill None values by a filling strategy.

        Parameters
        ----------
        strategy
            - &#34;backward&#34;
            - &#34;forward&#34;
            - &#34;mean&#34;
            - &#34;min&#39;
            - &#34;max&#34;

        Returns
        -------
            DataFrame with None replaced with the filling strategy.
        &#34;&#34;&#34;
        return wrap_df(self._df.fill_none(strategy))

    def explode(self, column: str) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Explode `DataFrame` to long format by exploding a column with Lists.

        Parameters
        ----------
        column
            Column of LargeList type

        Returns
        -------
        DataFrame
        &#34;&#34;&#34;
        return wrap_df(self._df.explode(column))

    def melt(
        self, id_vars: &#34;Union[List[str], str]&#34;, value_vars: &#34;Union[List[str], str]&#34;
    ) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Unpivot DataFrame to long format.

        Parameters
        ----------
        id_vars
            Columns to use as identifier variables

        value_vars
            Values to use as identifier variables

        Returns
        -------

        &#34;&#34;&#34;
        if isinstance(value_vars, str):
            value_vars = [value_vars]
        if isinstance(id_vars, str):
            id_vars = [id_vars]
        return wrap_df(self._df.melt(id_vars, value_vars))

    def shift(self, periods: int) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Shift the values by a given period and fill the parts that will be empty due to this operation
        with `Nones`.

        Parameters
        ----------
        periods
            Number of places to shift (may be negative).
        &#34;&#34;&#34;
        return wrap_df(self._df.shift(periods))

    def is_duplicated(self) -&gt; Series:
        &#34;&#34;&#34;
        Get a mask of all duplicated rows in this DataFrame
        &#34;&#34;&#34;
        return wrap_s(self._df.is_duplicated())

    def is_unique(self) -&gt; Series:
        &#34;&#34;&#34;
        Get a mask of all unique rows in this DataFrame
        &#34;&#34;&#34;
        return wrap_s(self._df.is_unique())

    def lazy(self) -&gt; &#34;LazyFrame&#34;:
        pass

    def n_chunks(self) -&gt; int:
        &#34;&#34;&#34;
        Get number of chunks used by the ChunkedArrays of this DataFrame
        &#34;&#34;&#34;
        return self._df.n_chunks()

    def max(self) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Aggregate the columns of this DataFrame to their maximum value
        &#34;&#34;&#34;
        return wrap_df(self._df.max())

    def min(self) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Aggregate the columns of this DataFrame to their minimum value
        &#34;&#34;&#34;
        return wrap_df(self._df.min())

    def sum(self) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Aggregate the columns of this DataFrame to their sum value
        &#34;&#34;&#34;
        return wrap_df(self._df.sum())

    def mean(self) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Aggregate the columns of this DataFrame to their mean value
        &#34;&#34;&#34;
        return wrap_df(self._df.mean())

    def std(self) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Aggregate the columns of this DataFrame to their standard deviation value
        &#34;&#34;&#34;
        return wrap_df(self._df.std())

    def var(self) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Aggregate the columns of this DataFrame to their variance value
        &#34;&#34;&#34;
        return wrap_df(self._df.var())

    def median(self) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Aggregate the columns of this DataFrame to their median value
        &#34;&#34;&#34;
        return wrap_df(self._df.median())

    def quantile(self, quantile: float) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Aggregate the columns of this DataFrame to their quantile value
        &#34;&#34;&#34;
        return wrap_df(self._df.quantile(quantile))

    def to_dummies(self) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Get one hot encoded dummy variables.
        &#34;&#34;&#34;
        return wrap_df(self._df.to_dummies())

    def drop_duplicates(
        self, maintain_order=True, subset: &#34;Optional[List[str]]&#34; = None
    ) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Drop duplicate rows from this DataFrame.
        Note that this fails if there is a column of type `List` in the DataFrame.
        &#34;&#34;&#34;
        if subset is not None and not isinstance(subset, list):
            subset = [subset]
        return wrap_df(self._df.drop_duplicates(maintain_order, subset))

    def _rechunk(self) -&gt; &#34;DataFrame&#34;:
        return wrap_df(self._df.rechunk())


class GroupBy:
    def __init__(self, df: DataFrame, by: &#34;List[str]&#34;):
        self._df = df
        self.by = by

    def agg(
        self, column_to_agg: &#34;Union[List[Tuple[str, List[str]]], Dict[str, List[str]]]&#34;
    ) -&gt; DataFrame:
        &#34;&#34;&#34;
        Use multiple aggregations on columns

        Parameters
        ----------
        column_to_agg
            map column to aggregation functions

            Examples:
                [(&#34;foo&#34;, [&#34;sum&#34;, &#34;n_unique&#34;, &#34;min&#34;]),
                 (&#34;bar&#34;: [&#34;max&#34;])]

                {&#34;foo&#34;: [&#34;sum&#34;, &#34;n_unique&#34;, &#34;min&#34;],
                &#34;bar&#34;: &#34;max&#34; }

        Returns
        -------
        Result of groupby split apply operations.
        &#34;&#34;&#34;
        if isinstance(column_to_agg, dict):
            column_to_agg = [
                (column, [agg] if isinstance(agg, str) else agg)
                for (column, agg) in column_to_agg.items()
            ]
        else:
            column_to_agg = [
                (column, [agg] if isinstance(agg, str) else agg)
                for (column, agg) in column_to_agg
            ]

        return wrap_df(self._df.groupby_agg(self.by, column_to_agg))

    def select(self, columns: &#34;Union[str, List[str]]&#34;) -&gt; &#34;GBSelection&#34;:
        &#34;&#34;&#34;
        Select the columns that will be aggregated.

        Parameters
        ----------
        columns
            One or multiple columns
        &#34;&#34;&#34;
        if isinstance(columns, str):
            columns = [columns]
        return GBSelection(self._df, self.by, columns)

    def select_all(self):
        &#34;&#34;&#34;
        Select all columns for aggregation.
        &#34;&#34;&#34;
        return GBSelection(self._df, self.by, None)

    def pivot(self, pivot_column: str, values_column: str) -&gt; &#34;PivotOps&#34;:
        &#34;&#34;&#34;
        Do a pivot operation based on the group key, a pivot column and an aggregation function on the values column.

        Parameters
        ----------
        pivot_column
            Column to pivot.
        values_column
            Column that will be aggregated
        &#34;&#34;&#34;
        return PivotOps(self._df, self.by, pivot_column, values_column)

    def first(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Aggregate the first values in the group.
        &#34;&#34;&#34;
        return self.select_all().first()

    def last(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Aggregate the last values in the group.
        &#34;&#34;&#34;
        return self.select_all().last()

    def sum(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Reduce the groups to the sum.
        &#34;&#34;&#34;
        return self.select_all().sum()

    def min(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Reduce the groups to the minimal value.
        &#34;&#34;&#34;
        return self.select_all().min()

    def max(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Reduce the groups to the maximal value.
        &#34;&#34;&#34;
        return self.select_all().max()

    def count(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Count the number of values in each group.
        &#34;&#34;&#34;
        return self.select_all().count()

    def mean(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Reduce the groups to the mean values.
        &#34;&#34;&#34;
        return self.select_all().mean()

    def n_unique(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Count the unique values per group.
        &#34;&#34;&#34;
        return self.select_all().n_unique()

    def quantile(self, quantile: float) -&gt; DataFrame:
        &#34;&#34;&#34;
        Count the unique values per group.
        &#34;&#34;&#34;
        return self.select_all().quantile(quantile)

    def median(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Return the median per group.
        &#34;&#34;&#34;
        return self.select_all().median()

    def agg_list(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Aggregate the groups into Series.
        &#34;&#34;&#34;
        return self.select_all().agg_list()


class PivotOps:
    def __init__(
        self, df: DataFrame, by: &#34;List[str]&#34;, pivot_column: str, values_column: str
    ):
        self._df = df
        self.by = by
        self.pivot_column = pivot_column
        self.values_column = values_column

    def first(self):
        &#34;&#34;&#34;
        Get the first value per group.
        &#34;&#34;&#34;
        return wrap_df(
            self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;first&#34;)
        )

    def sum(self):
        &#34;&#34;&#34;
        Get the sum per group.
        &#34;&#34;&#34;
        return wrap_df(
            self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;sum&#34;)
        )

    def min(self):
        &#34;&#34;&#34;
        Get the minimal value per group.
        &#34;&#34;&#34;
        return wrap_df(
            self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;min&#34;)
        )

    def max(self):
        &#34;&#34;&#34;
        Get the maximal value per group.
        &#34;&#34;&#34;
        return wrap_df(
            self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;max&#34;)
        )

    def mean(self):
        &#34;&#34;&#34;
        Get the mean value per group.
        &#34;&#34;&#34;
        return wrap_df(
            self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;mean&#34;)
        )

    def count(self):
        &#34;&#34;&#34;
        Count the values per group.
        &#34;&#34;&#34;
        return wrap_df(
            self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;count&#34;)
        )

    def median(self):
        &#34;&#34;&#34;
        Get the median value per group.
        &#34;&#34;&#34;
        return wrap_df(
            self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;median&#34;)
        )


class GBSelection:
    def __init__(
        self, df: DataFrame, by: &#34;List[str]&#34;, selection: &#34;Optional[List[str]]&#34;
    ):
        self._df = df
        self.by = by
        self.selection = selection

    def first(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Aggregate the first values in the group.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;first&#34;))

    def last(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Aggregate the last values in the group.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;last&#34;))

    def sum(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Reduce the groups to the sum.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;sum&#34;))

    def min(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Reduce the groups to the minimal value.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;min&#34;))

    def max(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Reduce the groups to the maximal value.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;max&#34;))

    def count(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Count the number of values in each group.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;count&#34;))

    def mean(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Reduce the groups to the mean values.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;mean&#34;))

    def n_unique(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Count the unique values per group.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;n_unique&#34;))

    def quantile(self, quantile: float) -&gt; DataFrame:
        &#34;&#34;&#34;
        Count the unique values per group.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby_quantile(self.by, self.selection, quantile))

    def median(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Return the median per group.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;median&#34;))

    def agg_list(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Aggregate the groups into Series.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;agg_list&#34;))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pypolars.frame.prepare_other"><code class="name flex">
<span>def <span class="ident">prepare_other</span></span>(<span>other: Any) ‑> <a title="pypolars.series.Series" href="series.html#pypolars.series.Series">Series</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prepare_other(other: Any) -&gt; Series:
    # if not a series create singleton series such that it will broadcast
    if not isinstance(other, Series):
        if isinstance(other, str):
            pass
        elif isinstance(other, Sequence):
            raise ValueError(&#34;operation not supported&#34;)

        other = Series(&#34;&#34;, [other])
    return other</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pypolars.frame.DataFrame"><code class="flex name class">
<span>class <span class="ident">DataFrame</span></span>
<span>(</span><span>data: Dict[str, Sequence], nullable: bool = False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DataFrame:
    def __init__(self, data: Dict[str, Sequence], nullable: bool = False):

        columns = []
        if isinstance(data, dict):
            for k, v in data.items():
                columns.append(Series(k, v, nullable=nullable).inner())
        elif isinstance(data, list):
            for s in data:
                if not isinstance(s, Series):
                    raise ValueError(&#34;a list should contain Series&#34;)
                columns.append(s.inner())
        else:
            try:
                import pandas as pd

                if isinstance(data, pd.DataFrame):
                    for c in data.columns:
                        if nullable:
                            s = Series(c, data[c].to_list(), nullable=True).inner()
                        else:
                            s = Series(c, data[c].values, nullable=False).inner()
                        columns.append(s)
                else:
                    raise ValueError(&#34;a dictionary was expected.&#34;)
            except ImportError:
                raise ValueError(&#34;a dictionary was expected.&#34;)

        self._df = PyDataFrame(columns)

    @staticmethod
    def _from_pydf(df: &#34;PyDataFrame&#34;) -&gt; &#34;DataFrame&#34;:
        self = DataFrame.__new__(DataFrame)
        self._df = df
        return self

    @staticmethod
    def read_csv(
        file: Union[str, TextIO],
        infer_schema_length: int = 100,
        batch_size: int = 1000,
        has_headers: bool = True,
        ignore_errors: bool = False,
        stop_after_n_rows: Optional[int] = None,
        skip_rows: int = 0,
        projection: &#34;Optional[List[int]]&#34; = None,
        sep: str = &#34;,&#34;,
        columns: &#34;Optional[List[str]]&#34; = None,
        rechunk: bool = True,
        encoding: str = &#34;utf8&#34;,
        one_thread: bool = True,
    ) -&gt; &#34;DataFrame&#34;:
        self = DataFrame.__new__(DataFrame)
        self._df = PyDataFrame.read_csv(
            file,
            infer_schema_length,
            batch_size,
            has_headers,
            ignore_errors,
            stop_after_n_rows,
            skip_rows,
            projection,
            sep,
            rechunk,
            columns,
            encoding,
            one_thread,
        )
        return self

    @staticmethod
    def read_parquet(
        file: Union[str, BinaryIO],
    ) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Read into a DataFrame from a parquet file.

        Parameters
        ----------
        file
            Path to a file or a file like object.

        Returns
        -------
        DataFrame
        &#34;&#34;&#34;
        self = DataFrame.__new__(DataFrame)
        self._df = PyDataFrame.read_parquet(file)
        return self

    @staticmethod
    def read_ipc(file: Union[str, BinaryIO]) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Read into a DataFrame from Arrow IPC stream format. This is also called the feather format.

        Parameters
        ----------
        file
            Path to a file or a file like object.

        Returns
        -------
        DataFrame
        &#34;&#34;&#34;
        self = DataFrame.__new__(DataFrame)
        self._df = PyDataFrame.read_ipc(file)
        return self

    def to_pandas(self) -&gt; &#34;pd.DataFrame&#34;:
        &#34;&#34;&#34;
        cast to a Pandas DataFrame.
        &#34;&#34;&#34;
        import pandas as pd

        data = {}
        for col in self.columns:
            series = self[col]
            if series.dtype == List:
                data[col] = series.to_list()
            elif series.dtype == Utf8:
                data[col] = series.to_list()
            else:
                data[col] = series.to_numpy()
        return pd.DataFrame(data)

    def to_csv(
        self,
        file: Union[TextIO, str],
        batch_size: int = 100000,
        has_headers: bool = True,
        delimiter: str = &#34;,&#34;,
    ):
        &#34;&#34;&#34;
        Write DataFrame to CSV

        Parameters
        ----------
        file
            write location
        batch_size
            Size of the write buffer. Increase to have faster io.
        has_headers
            Whether or not to include header in the CSV output.
        delimiter
            Space elements with this symbol.
        &#34;&#34;&#34;
        self._df.to_csv(file, batch_size, has_headers, ord(delimiter))

    def to_ipc(self, file: Union[BinaryIO, str], batch_size):
        &#34;&#34;&#34;
        Write to Arrow IPC binary stream, or a feather file.

        Parameters
        ----------
        file
            write location
        batch_size
            Size of the write buffer. Increase to have faster io.
        &#34;&#34;&#34;
        self._df.to_ipc(file, batch_size)

    def to_numpy(self) -&gt; np.ndarray:
        &#34;&#34;&#34;
        Convert DataFrame to a 2d numpy array.
        This operation clones data.
        &#34;&#34;&#34;
        return np.vstack([self[:, i].to_numpy() for i in range(self.width)]).T

    def __mul__(self, other):
        other = prepare_other(other)
        return wrap_df(self._df.mul(other._s))

    def __truediv__(self, other):
        other = prepare_other(other)
        return wrap_df(self._df.div(other._s))

    def __add__(self, other):
        other = prepare_other(other)
        return wrap_df(self._df.add(other._s))

    def __sub__(self, other):
        other = prepare_other(other)
        return wrap_df(self._df.sub(other._s))

    def __str__(self) -&gt; str:
        return self._df.as_str()

    def __repr__(self) -&gt; str:
        return self.__str__()

    def __getattr__(self, item) -&gt; &#34;PySeries&#34;:
        &#34;&#34;&#34;
        Access columns as attribute
        &#34;&#34;&#34;
        try:
            return wrap_s(self._df.column(item))
        except RuntimeError:
            raise AttributeError(f&#34;{item} not found&#34;)

    def __iter__(self):
        return self.get_columns().__iter__()

    def __getitem__(self, item):
        # select rows and columns at once
        # every 2d selection, i.e. tuple is row column order, just like numpy
        if isinstance(item, tuple):
            row_selection, col_selection = item

            # df[:, unknown]
            if isinstance(row_selection, slice):

                # multiple slices
                # df[:, :]
                if isinstance(col_selection, slice):
                    # TODO: select by indexes as column names can be duplicates
                    df = self.__getitem__(self.columns[col_selection])
                    return df[row_selection]

                # single slice
                # df[:, unknown]
                series = self.__getitem__(col_selection)
                # s[:]
                wrap_s(series[row_selection])

            # column selection can be &#34;a&#34; and [&#34;a&#34;, &#34;b&#34;]
            if isinstance(col_selection, str):
                col_selection = [col_selection]
            df = self.__getitem__(col_selection)
            return df.__getitem__(row_selection)

        # select single column
        # df[&#34;foo&#34;]
        if isinstance(item, str):
            return wrap_s(self._df.column(item))

        # df[idx]
        if isinstance(item, int):
            return wrap_s(self._df.select_at_idx(item))

        # df[:]
        if isinstance(item, slice):
            if getattr(item, &#34;end&#34;, False):
                raise ValueError(&#34;a slice with steps larger than 1 is not supported&#34;)
            if item.start is None:
                start = 0
            else:
                start = item.start
            if item.stop is None:
                stop = self.height
            else:
                stop = item.stop
            length = stop - start
            return self.slice(start, length)

        # select multiple columns
        # df[&#34;foo&#34;, &#34;bar&#34;]
        if isinstance(item, Sequence) and isinstance(item[0], str):
            return wrap_df(self._df.select(item))

        # select rows by mask or index
        # df[[1, 2, 3]]
        # df[true, false, true]
        if isinstance(item, np.ndarray):
            if item.dtype == int:
                return wrap_df(self._df.take(item))
        if isinstance(item, (Series, Sequence)):
            if isinstance(item, Sequence):
                # only bool or integers allowed
                if type(item[0]) == bool:
                    item = Series(&#34;&#34;, item)
                else:
                    return wrap_df(self._df.take(item))
            dtype = item.dtype
            if dtype == Boolean:
                return wrap_df(self._df.filter(item.inner()))
            if dtype == UInt32:
                return wrap_df(self._df.take_with_series(item.inner()))

    def __setitem__(self, key, value):
        # df[&#34;foo&#34;] = series
        if isinstance(key, str):
            try:
                self.drop_in_place(key)
            except:
                pass
            self.hstack([Series(key, value)], in_place=True)
        # df[idx] = series
        elif isinstance(key, int):
            assert isinstance(value, Series)
            self.replace_at_idx(key, value)
        # df[a, b]
        elif isinstance(key, tuple):
            row_selection, col_selection = key
            # get series column selection
            s = self.__getitem__(col_selection)

            # dispatch to __setitem__ of Series to do modification
            s[row_selection] = value

            # now find the location to place series
            # df[idx]
            if isinstance(col_selection, int):
                self.replace_at_idx(0, s)
            # df[&#34;foo&#34;]
            elif isinstance(col_selection, str):
                self.replace(col_selection, s)
        else:
            return NotImplemented

    def __len__(self):
        return self.height

    def insert_at_idx(self, index: int, series: Series):
        self._df.insert_at_idx(index, series._s)

    @property
    def shape(self) -&gt; Tuple[int, int]:
        &#34;&#34;&#34;
        Get shape of the DataFrame
        &#34;&#34;&#34;
        return self._df.shape()

    @property
    def height(self) -&gt; int:
        &#34;&#34;&#34;
        Get height of the DataFrame
        &#34;&#34;&#34;
        return self._df.height()

    @property
    def width(self) -&gt; int:
        &#34;&#34;&#34;
        Get width of the DataFrame
        &#34;&#34;&#34;
        return self._df.width()

    @property
    def columns(self) -&gt; &#34;List[str]&#34;:
        &#34;&#34;&#34;
        get column names
        &#34;&#34;&#34;
        return self._df.columns()

    @columns.setter
    def columns(self, columns: &#34;List[str]&#34;):
        self._df.set_column_names(columns)

    @property
    def dtypes(self) -&gt; &#34;List[type]&#34;:
        &#34;&#34;&#34;
        get dtypes
        &#34;&#34;&#34;
        return [dtypes[idx] for idx in self._df.dtypes()]

    def replace_at_idx(self, index: int, series: Series):
        &#34;&#34;&#34;
        Replace a column at an index  location.

        Parameters
        ----------
        index
            Column index
        series
            Series that will replace the column
        &#34;&#34;&#34;
        self._df.replace_at_idx(index, series._s)

    def sort(
        self, by_column: str, in_place: bool = False, reverse: bool = False
    ) -&gt; Optional[&#34;DataFrame&#34;]:
        &#34;&#34;&#34;
        Sort the DataFrame by column

        Parameters
        ----------
        by_column
            by which column to sort
        in_place
            sort in place or return a sorted DataFrame
        reverse
            reverse sort
        &#34;&#34;&#34;
        if in_place:
            self._df.sort_in_place(by_column, reverse)
        else:
            return wrap_df(self._df.sort(by_column, reverse))

    def frame_equal(self, other: &#34;DataFrame&#34;, null_equal: bool = False) -&gt; bool:
        &#34;&#34;&#34;
        Check if DataFrame is equal to other.

        Parameters
        ----------
        other
            DataFrame to compare with.
        null_equal
            Consider null values as equal.
        &#34;&#34;&#34;
        return self._df.frame_equal(other._df, null_equal)

    def replace(self, column: str, new_col: Series):
        &#34;&#34;&#34;
        Replace a column by a new Series.

        Parameters
        ----------
        column
            Column to replace.
        new_col
            New column to insert.
        &#34;&#34;&#34;
        self._df.replace(column, new_col.inner())

    def slice(self, offset: int, length: int) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Slice this DataFrame over the rows direction.

        Parameters
        ----------
        offset
            Offset index.
        length
            Length of the slice.
        &#34;&#34;&#34;
        return wrap_df(self._df.slice(offset, length))

    def head(self, length: int = 5) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Get first N rows as DataFrame

        Parameters
        ----------
        length
            Length of the head
        &#34;&#34;&#34;
        return wrap_df(self._df.head(length))

    def tail(self, length: int = 5) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Get last N rows as DataFrame

        Parameters
        ----------
        length
            Length of the tail
        &#34;&#34;&#34;
        return wrap_df(self._df.tail(length))

    def drop_nulls(self, subset: &#34;Optional[List[str]]&#34;) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Return a new DataFrame where the null values are dropped
        &#34;&#34;&#34;
        if subset is not None and isinstance(subset, str):
            subset = [subset]
        return wrap_df(self._df.drop_nulls(subset))

    def pipe(self, func: Callable, *args, **kwargs):
        &#34;&#34;&#34;
        Apply a function on Self

        Parameters
        ----------
        func
            Callable
        args
            Arguments
        kwargs
            Keyword arguments
        &#34;&#34;&#34;
        return func(self, *args, **kwargs)

    def groupby(self, by: &#34;Union[str, List[str]]&#34;) -&gt; &#34;GroupBy&#34;:
        &#34;&#34;&#34;
        Start a groupby operation

        Parameters
        ----------
        by
            Column(s) to group by.
        &#34;&#34;&#34;
        if isinstance(by, str):
            by = [by]
        return GroupBy(self._df, by)

    def join(
        self,
        df: &#34;DataFrame&#34;,
        left_on: str,
        right_on: str,
        how=&#34;inner&#34;,
    ) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        SQL like joins

        Parameters
        ----------
        df
            DataFrame to join with
        left_on
            Name of the left join column
        right_on
            Name of the right join column
        how
            Join strategy
                - &#34;inner&#34;
                - &#34;left&#34;
                - &#34;outer&#34;

        Returns
        -------
            Joined DataFrame
        &#34;&#34;&#34;
        try:
            if how == &#34;inner&#34;:
                inner = self._df.inner_join(df._df, left_on, right_on)
            elif how == &#34;left&#34;:
                inner = self._df.left_join(df._df, left_on, right_on)
            elif how == &#34;outer&#34;:
                inner = self._df.outer_join(df._df, left_on, right_on)
            else:
                return NotImplemented
        except Exception as e:
            self._df.with_parallel(False)
            raise e
        return wrap_df(inner)

    def hstack(
        self, columns: &#34;Union[List[Series], DataFrame]&#34;, in_place=False
    ) -&gt; Optional[&#34;DataFrame&#34;]:
        &#34;&#34;&#34;
        Return a new DataFrame grown horizontally by stacking Series to it.

        Parameters
        ----------
        columns
            Series to stack
        in_place
            Modify in place
        &#34;&#34;&#34;
        if not isinstance(columns, list):
            columns = columns.get_columns()
        if in_place:
            self._df.hstack_mut([s.inner() for s in columns])
        else:
            return wrap_df(self._df.hstack([s.inner() for s in columns]))

    def vstack(self, df: &#34;DataFrame&#34;):
        &#34;&#34;&#34;
        Grow this DataFrame vertically by stacking a DataFrame to it.

        Parameters
        ----------
        df
            DataFrame to stack
        &#34;&#34;&#34;
        self._df.vstack(df._df)

    def drop(self, name: str) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Remove column from DataFrame and return as new.

        Parameters
        ----------
        name
            Column to drop
        &#34;&#34;&#34;
        return wrap_df(self._df.drop(name))

    def drop_in_place(self, name: str) -&gt; Series:
        &#34;&#34;&#34;
        Drop in place

        Parameters
        ----------
        name
            Column to drop
        &#34;&#34;&#34;
        return wrap_s(self._df.drop_in_place(name))

    def select_at_idx(self, idx: int) -&gt; Series:
        &#34;&#34;&#34;
        Select column at index location.

        Parameters
        ----------
        idx
            Location of selection
        &#34;&#34;&#34;
        return wrap_s(self._df.select_at_idx(idx))

    def clone(self) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Very cheap deep clone
        &#34;&#34;&#34;
        return wrap_df(self._df.clone())

    def get_columns(self) -&gt; &#34;List[Series]&#34;:
        &#34;&#34;&#34;
        Get the DataFrame as a List of Series
        &#34;&#34;&#34;
        return list(map(lambda s: wrap_s(s), self._df.get_columns()))

    def fill_none(self, strategy: str) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Fill None values by a filling strategy.

        Parameters
        ----------
        strategy
            - &#34;backward&#34;
            - &#34;forward&#34;
            - &#34;mean&#34;
            - &#34;min&#39;
            - &#34;max&#34;

        Returns
        -------
            DataFrame with None replaced with the filling strategy.
        &#34;&#34;&#34;
        return wrap_df(self._df.fill_none(strategy))

    def explode(self, column: str) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Explode `DataFrame` to long format by exploding a column with Lists.

        Parameters
        ----------
        column
            Column of LargeList type

        Returns
        -------
        DataFrame
        &#34;&#34;&#34;
        return wrap_df(self._df.explode(column))

    def melt(
        self, id_vars: &#34;Union[List[str], str]&#34;, value_vars: &#34;Union[List[str], str]&#34;
    ) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Unpivot DataFrame to long format.

        Parameters
        ----------
        id_vars
            Columns to use as identifier variables

        value_vars
            Values to use as identifier variables

        Returns
        -------

        &#34;&#34;&#34;
        if isinstance(value_vars, str):
            value_vars = [value_vars]
        if isinstance(id_vars, str):
            id_vars = [id_vars]
        return wrap_df(self._df.melt(id_vars, value_vars))

    def shift(self, periods: int) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Shift the values by a given period and fill the parts that will be empty due to this operation
        with `Nones`.

        Parameters
        ----------
        periods
            Number of places to shift (may be negative).
        &#34;&#34;&#34;
        return wrap_df(self._df.shift(periods))

    def is_duplicated(self) -&gt; Series:
        &#34;&#34;&#34;
        Get a mask of all duplicated rows in this DataFrame
        &#34;&#34;&#34;
        return wrap_s(self._df.is_duplicated())

    def is_unique(self) -&gt; Series:
        &#34;&#34;&#34;
        Get a mask of all unique rows in this DataFrame
        &#34;&#34;&#34;
        return wrap_s(self._df.is_unique())

    def lazy(self) -&gt; &#34;LazyFrame&#34;:
        pass

    def n_chunks(self) -&gt; int:
        &#34;&#34;&#34;
        Get number of chunks used by the ChunkedArrays of this DataFrame
        &#34;&#34;&#34;
        return self._df.n_chunks()

    def max(self) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Aggregate the columns of this DataFrame to their maximum value
        &#34;&#34;&#34;
        return wrap_df(self._df.max())

    def min(self) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Aggregate the columns of this DataFrame to their minimum value
        &#34;&#34;&#34;
        return wrap_df(self._df.min())

    def sum(self) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Aggregate the columns of this DataFrame to their sum value
        &#34;&#34;&#34;
        return wrap_df(self._df.sum())

    def mean(self) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Aggregate the columns of this DataFrame to their mean value
        &#34;&#34;&#34;
        return wrap_df(self._df.mean())

    def std(self) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Aggregate the columns of this DataFrame to their standard deviation value
        &#34;&#34;&#34;
        return wrap_df(self._df.std())

    def var(self) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Aggregate the columns of this DataFrame to their variance value
        &#34;&#34;&#34;
        return wrap_df(self._df.var())

    def median(self) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Aggregate the columns of this DataFrame to their median value
        &#34;&#34;&#34;
        return wrap_df(self._df.median())

    def quantile(self, quantile: float) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Aggregate the columns of this DataFrame to their quantile value
        &#34;&#34;&#34;
        return wrap_df(self._df.quantile(quantile))

    def to_dummies(self) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Get one hot encoded dummy variables.
        &#34;&#34;&#34;
        return wrap_df(self._df.to_dummies())

    def drop_duplicates(
        self, maintain_order=True, subset: &#34;Optional[List[str]]&#34; = None
    ) -&gt; &#34;DataFrame&#34;:
        &#34;&#34;&#34;
        Drop duplicate rows from this DataFrame.
        Note that this fails if there is a column of type `List` in the DataFrame.
        &#34;&#34;&#34;
        if subset is not None and not isinstance(subset, list):
            subset = [subset]
        return wrap_df(self._df.drop_duplicates(maintain_order, subset))

    def _rechunk(self) -&gt; &#34;DataFrame&#34;:
        return wrap_df(self._df.rechunk())</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="pypolars.frame.DataFrame.read_csv"><code class="name flex">
<span>def <span class="ident">read_csv</span></span>(<span>file: Union[str, TextIO], infer_schema_length: int = 100, batch_size: int = 1000, has_headers: bool = True, ignore_errors: bool = False, stop_after_n_rows: Union[int, NoneType] = None, skip_rows: int = 0, projection: Optional[List[int]] = None, sep: str = ',', columns: Optional[List[str]] = None, rechunk: bool = True, encoding: str = 'utf8', one_thread: bool = True) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def read_csv(
    file: Union[str, TextIO],
    infer_schema_length: int = 100,
    batch_size: int = 1000,
    has_headers: bool = True,
    ignore_errors: bool = False,
    stop_after_n_rows: Optional[int] = None,
    skip_rows: int = 0,
    projection: &#34;Optional[List[int]]&#34; = None,
    sep: str = &#34;,&#34;,
    columns: &#34;Optional[List[str]]&#34; = None,
    rechunk: bool = True,
    encoding: str = &#34;utf8&#34;,
    one_thread: bool = True,
) -&gt; &#34;DataFrame&#34;:
    self = DataFrame.__new__(DataFrame)
    self._df = PyDataFrame.read_csv(
        file,
        infer_schema_length,
        batch_size,
        has_headers,
        ignore_errors,
        stop_after_n_rows,
        skip_rows,
        projection,
        sep,
        rechunk,
        columns,
        encoding,
        one_thread,
    )
    return self</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.read_ipc"><code class="name flex">
<span>def <span class="ident">read_ipc</span></span>(<span>file: Union[str, BinaryIO]) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Read into a DataFrame from Arrow IPC stream format. This is also called the feather format.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>file</code></strong></dt>
<dd>Path to a file or a file like object.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def read_ipc(file: Union[str, BinaryIO]) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Read into a DataFrame from Arrow IPC stream format. This is also called the feather format.

    Parameters
    ----------
    file
        Path to a file or a file like object.

    Returns
    -------
    DataFrame
    &#34;&#34;&#34;
    self = DataFrame.__new__(DataFrame)
    self._df = PyDataFrame.read_ipc(file)
    return self</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.read_parquet"><code class="name flex">
<span>def <span class="ident">read_parquet</span></span>(<span>file: Union[str, BinaryIO]) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Read into a DataFrame from a parquet file.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>file</code></strong></dt>
<dd>Path to a file or a file like object.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def read_parquet(
    file: Union[str, BinaryIO],
) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Read into a DataFrame from a parquet file.

    Parameters
    ----------
    file
        Path to a file or a file like object.

    Returns
    -------
    DataFrame
    &#34;&#34;&#34;
    self = DataFrame.__new__(DataFrame)
    self._df = PyDataFrame.read_parquet(file)
    return self</code></pre>
</details>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="pypolars.frame.DataFrame.columns"><code class="name">var <span class="ident">columns</span> : List[str]</code></dt>
<dd>
<div class="desc"><p>get column names</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def columns(self) -&gt; &#34;List[str]&#34;:
    &#34;&#34;&#34;
    get column names
    &#34;&#34;&#34;
    return self._df.columns()</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.dtypes"><code class="name">var <span class="ident">dtypes</span> : List[type]</code></dt>
<dd>
<div class="desc"><p>get dtypes</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def dtypes(self) -&gt; &#34;List[type]&#34;:
    &#34;&#34;&#34;
    get dtypes
    &#34;&#34;&#34;
    return [dtypes[idx] for idx in self._df.dtypes()]</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.height"><code class="name">var <span class="ident">height</span> : int</code></dt>
<dd>
<div class="desc"><p>Get height of the DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def height(self) -&gt; int:
    &#34;&#34;&#34;
    Get height of the DataFrame
    &#34;&#34;&#34;
    return self._df.height()</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.shape"><code class="name">var <span class="ident">shape</span> : Tuple[int, int]</code></dt>
<dd>
<div class="desc"><p>Get shape of the DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def shape(self) -&gt; Tuple[int, int]:
    &#34;&#34;&#34;
    Get shape of the DataFrame
    &#34;&#34;&#34;
    return self._df.shape()</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.width"><code class="name">var <span class="ident">width</span> : int</code></dt>
<dd>
<div class="desc"><p>Get width of the DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def width(self) -&gt; int:
    &#34;&#34;&#34;
    Get width of the DataFrame
    &#34;&#34;&#34;
    return self._df.width()</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pypolars.frame.DataFrame.clone"><code class="name flex">
<span>def <span class="ident">clone</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Very cheap deep clone</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clone(self) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Very cheap deep clone
    &#34;&#34;&#34;
    return wrap_df(self._df.clone())</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.drop"><code class="name flex">
<span>def <span class="ident">drop</span></span>(<span>self, name: str) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Remove column from DataFrame and return as new.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>name</code></strong></dt>
<dd>Column to drop</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def drop(self, name: str) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Remove column from DataFrame and return as new.

    Parameters
    ----------
    name
        Column to drop
    &#34;&#34;&#34;
    return wrap_df(self._df.drop(name))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.drop_duplicates"><code class="name flex">
<span>def <span class="ident">drop_duplicates</span></span>(<span>self, maintain_order=True, subset: Optional[List[str]] = None) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Drop duplicate rows from this DataFrame.
Note that this fails if there is a column of type <code>List</code> in the DataFrame.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def drop_duplicates(
    self, maintain_order=True, subset: &#34;Optional[List[str]]&#34; = None
) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Drop duplicate rows from this DataFrame.
    Note that this fails if there is a column of type `List` in the DataFrame.
    &#34;&#34;&#34;
    if subset is not None and not isinstance(subset, list):
        subset = [subset]
    return wrap_df(self._df.drop_duplicates(maintain_order, subset))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.drop_in_place"><code class="name flex">
<span>def <span class="ident">drop_in_place</span></span>(<span>self, name: str) ‑> <a title="pypolars.series.Series" href="series.html#pypolars.series.Series">Series</a></span>
</code></dt>
<dd>
<div class="desc"><p>Drop in place</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>name</code></strong></dt>
<dd>Column to drop</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def drop_in_place(self, name: str) -&gt; Series:
    &#34;&#34;&#34;
    Drop in place

    Parameters
    ----------
    name
        Column to drop
    &#34;&#34;&#34;
    return wrap_s(self._df.drop_in_place(name))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.drop_nulls"><code class="name flex">
<span>def <span class="ident">drop_nulls</span></span>(<span>self, subset: Optional[List[str]]) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Return a new DataFrame where the null values are dropped</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def drop_nulls(self, subset: &#34;Optional[List[str]]&#34;) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Return a new DataFrame where the null values are dropped
    &#34;&#34;&#34;
    if subset is not None and isinstance(subset, str):
        subset = [subset]
    return wrap_df(self._df.drop_nulls(subset))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.explode"><code class="name flex">
<span>def <span class="ident">explode</span></span>(<span>self, column: str) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Explode <code><a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></code> to long format by exploding a column with Lists.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>column</code></strong></dt>
<dd>Column of LargeList type</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def explode(self, column: str) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Explode `DataFrame` to long format by exploding a column with Lists.

    Parameters
    ----------
    column
        Column of LargeList type

    Returns
    -------
    DataFrame
    &#34;&#34;&#34;
    return wrap_df(self._df.explode(column))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.fill_none"><code class="name flex">
<span>def <span class="ident">fill_none</span></span>(<span>self, strategy: str) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Fill None values by a filling strategy.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>strategy</code></strong></dt>
<dd>
<ul>
<li>"backward"</li>
<li>"forward"</li>
<li>"mean"</li>
<li>"min'</li>
<li>"max"</li>
</ul>
</dd>
</dl>
<h2 id="returns">Returns</h2>
<pre><code>DataFrame with None replaced with the filling strategy.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fill_none(self, strategy: str) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Fill None values by a filling strategy.

    Parameters
    ----------
    strategy
        - &#34;backward&#34;
        - &#34;forward&#34;
        - &#34;mean&#34;
        - &#34;min&#39;
        - &#34;max&#34;

    Returns
    -------
        DataFrame with None replaced with the filling strategy.
    &#34;&#34;&#34;
    return wrap_df(self._df.fill_none(strategy))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.frame_equal"><code class="name flex">
<span>def <span class="ident">frame_equal</span></span>(<span>self, other: <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a>, null_equal: bool = False) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Check if DataFrame is equal to other.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>other</code></strong></dt>
<dd>DataFrame to compare with.</dd>
<dt><strong><code>null_equal</code></strong></dt>
<dd>Consider null values as equal.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def frame_equal(self, other: &#34;DataFrame&#34;, null_equal: bool = False) -&gt; bool:
    &#34;&#34;&#34;
    Check if DataFrame is equal to other.

    Parameters
    ----------
    other
        DataFrame to compare with.
    null_equal
        Consider null values as equal.
    &#34;&#34;&#34;
    return self._df.frame_equal(other._df, null_equal)</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.get_columns"><code class="name flex">
<span>def <span class="ident">get_columns</span></span>(<span>self) ‑> List[Series]</span>
</code></dt>
<dd>
<div class="desc"><p>Get the DataFrame as a List of Series</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_columns(self) -&gt; &#34;List[Series]&#34;:
    &#34;&#34;&#34;
    Get the DataFrame as a List of Series
    &#34;&#34;&#34;
    return list(map(lambda s: wrap_s(s), self._df.get_columns()))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.groupby"><code class="name flex">
<span>def <span class="ident">groupby</span></span>(<span>self, by: Union[str, List[str]]) ‑> <a title="pypolars.frame.GroupBy" href="#pypolars.frame.GroupBy">GroupBy</a></span>
</code></dt>
<dd>
<div class="desc"><p>Start a groupby operation</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>by</code></strong></dt>
<dd>Column(s) to group by.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def groupby(self, by: &#34;Union[str, List[str]]&#34;) -&gt; &#34;GroupBy&#34;:
    &#34;&#34;&#34;
    Start a groupby operation

    Parameters
    ----------
    by
        Column(s) to group by.
    &#34;&#34;&#34;
    if isinstance(by, str):
        by = [by]
    return GroupBy(self._df, by)</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.head"><code class="name flex">
<span>def <span class="ident">head</span></span>(<span>self, length: int = 5) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Get first N rows as DataFrame</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>length</code></strong></dt>
<dd>Length of the head</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def head(self, length: int = 5) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Get first N rows as DataFrame

    Parameters
    ----------
    length
        Length of the head
    &#34;&#34;&#34;
    return wrap_df(self._df.head(length))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.hstack"><code class="name flex">
<span>def <span class="ident">hstack</span></span>(<span>self, columns: Union[List[Series], <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a>], in_place=False) ‑> Union[<a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a>, NoneType]</span>
</code></dt>
<dd>
<div class="desc"><p>Return a new DataFrame grown horizontally by stacking Series to it.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>columns</code></strong></dt>
<dd>Series to stack</dd>
<dt><strong><code>in_place</code></strong></dt>
<dd>Modify in place</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def hstack(
    self, columns: &#34;Union[List[Series], DataFrame]&#34;, in_place=False
) -&gt; Optional[&#34;DataFrame&#34;]:
    &#34;&#34;&#34;
    Return a new DataFrame grown horizontally by stacking Series to it.

    Parameters
    ----------
    columns
        Series to stack
    in_place
        Modify in place
    &#34;&#34;&#34;
    if not isinstance(columns, list):
        columns = columns.get_columns()
    if in_place:
        self._df.hstack_mut([s.inner() for s in columns])
    else:
        return wrap_df(self._df.hstack([s.inner() for s in columns]))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.insert_at_idx"><code class="name flex">
<span>def <span class="ident">insert_at_idx</span></span>(<span>self, index: int, series: <a title="pypolars.series.Series" href="series.html#pypolars.series.Series">Series</a>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def insert_at_idx(self, index: int, series: Series):
    self._df.insert_at_idx(index, series._s)</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.is_duplicated"><code class="name flex">
<span>def <span class="ident">is_duplicated</span></span>(<span>self) ‑> <a title="pypolars.series.Series" href="series.html#pypolars.series.Series">Series</a></span>
</code></dt>
<dd>
<div class="desc"><p>Get a mask of all duplicated rows in this DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_duplicated(self) -&gt; Series:
    &#34;&#34;&#34;
    Get a mask of all duplicated rows in this DataFrame
    &#34;&#34;&#34;
    return wrap_s(self._df.is_duplicated())</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.is_unique"><code class="name flex">
<span>def <span class="ident">is_unique</span></span>(<span>self) ‑> <a title="pypolars.series.Series" href="series.html#pypolars.series.Series">Series</a></span>
</code></dt>
<dd>
<div class="desc"><p>Get a mask of all unique rows in this DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_unique(self) -&gt; Series:
    &#34;&#34;&#34;
    Get a mask of all unique rows in this DataFrame
    &#34;&#34;&#34;
    return wrap_s(self._df.is_unique())</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.join"><code class="name flex">
<span>def <span class="ident">join</span></span>(<span>self, df: <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a>, left_on: str, right_on: str, how='inner') ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>SQL like joins</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>df</code></strong></dt>
<dd>DataFrame to join with</dd>
<dt><strong><code>left_on</code></strong></dt>
<dd>Name of the left join column</dd>
<dt><strong><code>right_on</code></strong></dt>
<dd>Name of the right join column</dd>
<dt><strong><code>how</code></strong></dt>
<dd>Join strategy
- "inner"
- "left"
- "outer"</dd>
</dl>
<h2 id="returns">Returns</h2>
<pre><code>Joined DataFrame
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def join(
    self,
    df: &#34;DataFrame&#34;,
    left_on: str,
    right_on: str,
    how=&#34;inner&#34;,
) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    SQL like joins

    Parameters
    ----------
    df
        DataFrame to join with
    left_on
        Name of the left join column
    right_on
        Name of the right join column
    how
        Join strategy
            - &#34;inner&#34;
            - &#34;left&#34;
            - &#34;outer&#34;

    Returns
    -------
        Joined DataFrame
    &#34;&#34;&#34;
    try:
        if how == &#34;inner&#34;:
            inner = self._df.inner_join(df._df, left_on, right_on)
        elif how == &#34;left&#34;:
            inner = self._df.left_join(df._df, left_on, right_on)
        elif how == &#34;outer&#34;:
            inner = self._df.outer_join(df._df, left_on, right_on)
        else:
            return NotImplemented
    except Exception as e:
        self._df.with_parallel(False)
        raise e
    return wrap_df(inner)</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.lazy"><code class="name flex">
<span>def <span class="ident">lazy</span></span>(<span>self) ‑> <a title="pypolars.lazy.LazyFrame" href="lazy.html#pypolars.lazy.LazyFrame">LazyFrame</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def lazy(self) -&gt; &#34;LazyFrame&#34;:
    return wrap_ldf(self._df.lazy())</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.max"><code class="name flex">
<span>def <span class="ident">max</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate the columns of this DataFrame to their maximum value</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def max(self) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Aggregate the columns of this DataFrame to their maximum value
    &#34;&#34;&#34;
    return wrap_df(self._df.max())</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.mean"><code class="name flex">
<span>def <span class="ident">mean</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate the columns of this DataFrame to their mean value</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mean(self) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Aggregate the columns of this DataFrame to their mean value
    &#34;&#34;&#34;
    return wrap_df(self._df.mean())</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.median"><code class="name flex">
<span>def <span class="ident">median</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate the columns of this DataFrame to their median value</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def median(self) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Aggregate the columns of this DataFrame to their median value
    &#34;&#34;&#34;
    return wrap_df(self._df.median())</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.melt"><code class="name flex">
<span>def <span class="ident">melt</span></span>(<span>self, id_vars: Union[List[str], str], value_vars: Union[List[str], str]) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Unpivot DataFrame to long format.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>id_vars</code></strong></dt>
<dd>Columns to use as identifier variables</dd>
<dt><strong><code>value_vars</code></strong></dt>
<dd>Values to use as identifier variables</dd>
</dl>
<h2 id="returns">Returns</h2></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def melt(
    self, id_vars: &#34;Union[List[str], str]&#34;, value_vars: &#34;Union[List[str], str]&#34;
) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Unpivot DataFrame to long format.

    Parameters
    ----------
    id_vars
        Columns to use as identifier variables

    value_vars
        Values to use as identifier variables

    Returns
    -------

    &#34;&#34;&#34;
    if isinstance(value_vars, str):
        value_vars = [value_vars]
    if isinstance(id_vars, str):
        id_vars = [id_vars]
    return wrap_df(self._df.melt(id_vars, value_vars))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.min"><code class="name flex">
<span>def <span class="ident">min</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate the columns of this DataFrame to their minimum value</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def min(self) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Aggregate the columns of this DataFrame to their minimum value
    &#34;&#34;&#34;
    return wrap_df(self._df.min())</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.n_chunks"><code class="name flex">
<span>def <span class="ident">n_chunks</span></span>(<span>self) ‑> int</span>
</code></dt>
<dd>
<div class="desc"><p>Get number of chunks used by the ChunkedArrays of this DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def n_chunks(self) -&gt; int:
    &#34;&#34;&#34;
    Get number of chunks used by the ChunkedArrays of this DataFrame
    &#34;&#34;&#34;
    return self._df.n_chunks()</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.pipe"><code class="name flex">
<span>def <span class="ident">pipe</span></span>(<span>self, func: Callable, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Apply a function on Self</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>func</code></strong></dt>
<dd>Callable</dd>
<dt><strong><code>args</code></strong></dt>
<dd>Arguments</dd>
<dt><strong><code>kwargs</code></strong></dt>
<dd>Keyword arguments</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pipe(self, func: Callable, *args, **kwargs):
    &#34;&#34;&#34;
    Apply a function on Self

    Parameters
    ----------
    func
        Callable
    args
        Arguments
    kwargs
        Keyword arguments
    &#34;&#34;&#34;
    return func(self, *args, **kwargs)</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.quantile"><code class="name flex">
<span>def <span class="ident">quantile</span></span>(<span>self, quantile: float) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate the columns of this DataFrame to their quantile value</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def quantile(self, quantile: float) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Aggregate the columns of this DataFrame to their quantile value
    &#34;&#34;&#34;
    return wrap_df(self._df.quantile(quantile))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.replace"><code class="name flex">
<span>def <span class="ident">replace</span></span>(<span>self, column: str, new_col: <a title="pypolars.series.Series" href="series.html#pypolars.series.Series">Series</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Replace a column by a new Series.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>column</code></strong></dt>
<dd>Column to replace.</dd>
<dt><strong><code>new_col</code></strong></dt>
<dd>New column to insert.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def replace(self, column: str, new_col: Series):
    &#34;&#34;&#34;
    Replace a column by a new Series.

    Parameters
    ----------
    column
        Column to replace.
    new_col
        New column to insert.
    &#34;&#34;&#34;
    self._df.replace(column, new_col.inner())</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.replace_at_idx"><code class="name flex">
<span>def <span class="ident">replace_at_idx</span></span>(<span>self, index: int, series: <a title="pypolars.series.Series" href="series.html#pypolars.series.Series">Series</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Replace a column at an index
location.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>index</code></strong></dt>
<dd>Column index</dd>
<dt><strong><code>series</code></strong></dt>
<dd>Series that will replace the column</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def replace_at_idx(self, index: int, series: Series):
    &#34;&#34;&#34;
    Replace a column at an index  location.

    Parameters
    ----------
    index
        Column index
    series
        Series that will replace the column
    &#34;&#34;&#34;
    self._df.replace_at_idx(index, series._s)</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.select_at_idx"><code class="name flex">
<span>def <span class="ident">select_at_idx</span></span>(<span>self, idx: int) ‑> <a title="pypolars.series.Series" href="series.html#pypolars.series.Series">Series</a></span>
</code></dt>
<dd>
<div class="desc"><p>Select column at index location.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>idx</code></strong></dt>
<dd>Location of selection</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def select_at_idx(self, idx: int) -&gt; Series:
    &#34;&#34;&#34;
    Select column at index location.

    Parameters
    ----------
    idx
        Location of selection
    &#34;&#34;&#34;
    return wrap_s(self._df.select_at_idx(idx))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.shift"><code class="name flex">
<span>def <span class="ident">shift</span></span>(<span>self, periods: int) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Shift the values by a given period and fill the parts that will be empty due to this operation
with <code>Nones</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>periods</code></strong></dt>
<dd>Number of places to shift (may be negative).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def shift(self, periods: int) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Shift the values by a given period and fill the parts that will be empty due to this operation
    with `Nones`.

    Parameters
    ----------
    periods
        Number of places to shift (may be negative).
    &#34;&#34;&#34;
    return wrap_df(self._df.shift(periods))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.slice"><code class="name flex">
<span>def <span class="ident">slice</span></span>(<span>self, offset: int, length: int) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Slice this DataFrame over the rows direction.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>offset</code></strong></dt>
<dd>Offset index.</dd>
<dt><strong><code>length</code></strong></dt>
<dd>Length of the slice.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def slice(self, offset: int, length: int) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Slice this DataFrame over the rows direction.

    Parameters
    ----------
    offset
        Offset index.
    length
        Length of the slice.
    &#34;&#34;&#34;
    return wrap_df(self._df.slice(offset, length))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.sort"><code class="name flex">
<span>def <span class="ident">sort</span></span>(<span>self, by_column: str, in_place: bool = False, reverse: bool = False) ‑> Union[<a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a>, NoneType]</span>
</code></dt>
<dd>
<div class="desc"><p>Sort the DataFrame by column</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>by_column</code></strong></dt>
<dd>by which column to sort</dd>
<dt><strong><code>in_place</code></strong></dt>
<dd>sort in place or return a sorted DataFrame</dd>
<dt><strong><code>reverse</code></strong></dt>
<dd>reverse sort</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sort(
    self, by_column: str, in_place: bool = False, reverse: bool = False
) -&gt; Optional[&#34;DataFrame&#34;]:
    &#34;&#34;&#34;
    Sort the DataFrame by column

    Parameters
    ----------
    by_column
        by which column to sort
    in_place
        sort in place or return a sorted DataFrame
    reverse
        reverse sort
    &#34;&#34;&#34;
    if in_place:
        self._df.sort_in_place(by_column, reverse)
    else:
        return wrap_df(self._df.sort(by_column, reverse))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.std"><code class="name flex">
<span>def <span class="ident">std</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate the columns of this DataFrame to their standard deviation value</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def std(self) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Aggregate the columns of this DataFrame to their standard deviation value
    &#34;&#34;&#34;
    return wrap_df(self._df.std())</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.sum"><code class="name flex">
<span>def <span class="ident">sum</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate the columns of this DataFrame to their sum value</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sum(self) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Aggregate the columns of this DataFrame to their sum value
    &#34;&#34;&#34;
    return wrap_df(self._df.sum())</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.tail"><code class="name flex">
<span>def <span class="ident">tail</span></span>(<span>self, length: int = 5) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Get last N rows as DataFrame</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>length</code></strong></dt>
<dd>Length of the tail</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tail(self, length: int = 5) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Get last N rows as DataFrame

    Parameters
    ----------
    length
        Length of the tail
    &#34;&#34;&#34;
    return wrap_df(self._df.tail(length))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.to_csv"><code class="name flex">
<span>def <span class="ident">to_csv</span></span>(<span>self, file: Union[TextIO, str], batch_size: int = 100000, has_headers: bool = True, delimiter: str = ',')</span>
</code></dt>
<dd>
<div class="desc"><p>Write DataFrame to CSV</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>file</code></strong></dt>
<dd>write location</dd>
<dt><strong><code>batch_size</code></strong></dt>
<dd>Size of the write buffer. Increase to have faster io.</dd>
<dt><strong><code>has_headers</code></strong></dt>
<dd>Whether or not to include header in the CSV output.</dd>
<dt><strong><code>delimiter</code></strong></dt>
<dd>Space elements with this symbol.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_csv(
    self,
    file: Union[TextIO, str],
    batch_size: int = 100000,
    has_headers: bool = True,
    delimiter: str = &#34;,&#34;,
):
    &#34;&#34;&#34;
    Write DataFrame to CSV

    Parameters
    ----------
    file
        write location
    batch_size
        Size of the write buffer. Increase to have faster io.
    has_headers
        Whether or not to include header in the CSV output.
    delimiter
        Space elements with this symbol.
    &#34;&#34;&#34;
    self._df.to_csv(file, batch_size, has_headers, ord(delimiter))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.to_dummies"><code class="name flex">
<span>def <span class="ident">to_dummies</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Get one hot encoded dummy variables.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_dummies(self) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Get one hot encoded dummy variables.
    &#34;&#34;&#34;
    return wrap_df(self._df.to_dummies())</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.to_ipc"><code class="name flex">
<span>def <span class="ident">to_ipc</span></span>(<span>self, file: Union[BinaryIO, str], batch_size)</span>
</code></dt>
<dd>
<div class="desc"><p>Write to Arrow IPC binary stream, or a feather file.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>file</code></strong></dt>
<dd>write location</dd>
<dt><strong><code>batch_size</code></strong></dt>
<dd>Size of the write buffer. Increase to have faster io.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_ipc(self, file: Union[BinaryIO, str], batch_size):
    &#34;&#34;&#34;
    Write to Arrow IPC binary stream, or a feather file.

    Parameters
    ----------
    file
        write location
    batch_size
        Size of the write buffer. Increase to have faster io.
    &#34;&#34;&#34;
    self._df.to_ipc(file, batch_size)</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.to_numpy"><code class="name flex">
<span>def <span class="ident">to_numpy</span></span>(<span>self) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Convert DataFrame to a 2d numpy array.
This operation clones data.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_numpy(self) -&gt; np.ndarray:
    &#34;&#34;&#34;
    Convert DataFrame to a 2d numpy array.
    This operation clones data.
    &#34;&#34;&#34;
    return np.vstack([self[:, i].to_numpy() for i in range(self.width)]).T</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.to_pandas"><code class="name flex">
<span>def <span class="ident">to_pandas</span></span>(<span>self) ‑> pd.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>cast to a Pandas DataFrame.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_pandas(self) -&gt; &#34;pd.DataFrame&#34;:
    &#34;&#34;&#34;
    cast to a Pandas DataFrame.
    &#34;&#34;&#34;
    import pandas as pd

    data = {}
    for col in self.columns:
        series = self[col]
        if series.dtype == List:
            data[col] = series.to_list()
        elif series.dtype == Utf8:
            data[col] = series.to_list()
        else:
            data[col] = series.to_numpy()
    return pd.DataFrame(data)</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.var"><code class="name flex">
<span>def <span class="ident">var</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate the columns of this DataFrame to their variance value</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def var(self) -&gt; &#34;DataFrame&#34;:
    &#34;&#34;&#34;
    Aggregate the columns of this DataFrame to their variance value
    &#34;&#34;&#34;
    return wrap_df(self._df.var())</code></pre>
</details>
</dd>
<dt id="pypolars.frame.DataFrame.vstack"><code class="name flex">
<span>def <span class="ident">vstack</span></span>(<span>self, df: <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Grow this DataFrame vertically by stacking a DataFrame to it.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>df</code></strong></dt>
<dd>DataFrame to stack</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def vstack(self, df: &#34;DataFrame&#34;):
    &#34;&#34;&#34;
    Grow this DataFrame vertically by stacking a DataFrame to it.

    Parameters
    ----------
    df
        DataFrame to stack
    &#34;&#34;&#34;
    self._df.vstack(df._df)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pypolars.frame.GBSelection"><code class="flex name class">
<span>class <span class="ident">GBSelection</span></span>
<span>(</span><span>df: <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a>, by: List[str], selection: Optional[List[str]])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GBSelection:
    def __init__(
        self, df: DataFrame, by: &#34;List[str]&#34;, selection: &#34;Optional[List[str]]&#34;
    ):
        self._df = df
        self.by = by
        self.selection = selection

    def first(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Aggregate the first values in the group.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;first&#34;))

    def last(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Aggregate the last values in the group.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;last&#34;))

    def sum(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Reduce the groups to the sum.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;sum&#34;))

    def min(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Reduce the groups to the minimal value.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;min&#34;))

    def max(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Reduce the groups to the maximal value.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;max&#34;))

    def count(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Count the number of values in each group.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;count&#34;))

    def mean(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Reduce the groups to the mean values.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;mean&#34;))

    def n_unique(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Count the unique values per group.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;n_unique&#34;))

    def quantile(self, quantile: float) -&gt; DataFrame:
        &#34;&#34;&#34;
        Count the unique values per group.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby_quantile(self.by, self.selection, quantile))

    def median(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Return the median per group.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;median&#34;))

    def agg_list(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Aggregate the groups into Series.
        &#34;&#34;&#34;
        return wrap_df(self._df.groupby(self.by, self.selection, &#34;agg_list&#34;))</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pypolars.frame.GBSelection.agg_list"><code class="name flex">
<span>def <span class="ident">agg_list</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate the groups into Series.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def agg_list(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Aggregate the groups into Series.
    &#34;&#34;&#34;
    return wrap_df(self._df.groupby(self.by, self.selection, &#34;agg_list&#34;))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GBSelection.count"><code class="name flex">
<span>def <span class="ident">count</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Count the number of values in each group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def count(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Count the number of values in each group.
    &#34;&#34;&#34;
    return wrap_df(self._df.groupby(self.by, self.selection, &#34;count&#34;))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GBSelection.first"><code class="name flex">
<span>def <span class="ident">first</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate the first values in the group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def first(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Aggregate the first values in the group.
    &#34;&#34;&#34;
    return wrap_df(self._df.groupby(self.by, self.selection, &#34;first&#34;))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GBSelection.last"><code class="name flex">
<span>def <span class="ident">last</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate the last values in the group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def last(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Aggregate the last values in the group.
    &#34;&#34;&#34;
    return wrap_df(self._df.groupby(self.by, self.selection, &#34;last&#34;))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GBSelection.max"><code class="name flex">
<span>def <span class="ident">max</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Reduce the groups to the maximal value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def max(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Reduce the groups to the maximal value.
    &#34;&#34;&#34;
    return wrap_df(self._df.groupby(self.by, self.selection, &#34;max&#34;))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GBSelection.mean"><code class="name flex">
<span>def <span class="ident">mean</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Reduce the groups to the mean values.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mean(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Reduce the groups to the mean values.
    &#34;&#34;&#34;
    return wrap_df(self._df.groupby(self.by, self.selection, &#34;mean&#34;))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GBSelection.median"><code class="name flex">
<span>def <span class="ident">median</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Return the median per group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def median(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Return the median per group.
    &#34;&#34;&#34;
    return wrap_df(self._df.groupby(self.by, self.selection, &#34;median&#34;))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GBSelection.min"><code class="name flex">
<span>def <span class="ident">min</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Reduce the groups to the minimal value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def min(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Reduce the groups to the minimal value.
    &#34;&#34;&#34;
    return wrap_df(self._df.groupby(self.by, self.selection, &#34;min&#34;))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GBSelection.n_unique"><code class="name flex">
<span>def <span class="ident">n_unique</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Count the unique values per group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def n_unique(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Count the unique values per group.
    &#34;&#34;&#34;
    return wrap_df(self._df.groupby(self.by, self.selection, &#34;n_unique&#34;))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GBSelection.quantile"><code class="name flex">
<span>def <span class="ident">quantile</span></span>(<span>self, quantile: float) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Count the unique values per group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def quantile(self, quantile: float) -&gt; DataFrame:
    &#34;&#34;&#34;
    Count the unique values per group.
    &#34;&#34;&#34;
    return wrap_df(self._df.groupby_quantile(self.by, self.selection, quantile))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GBSelection.sum"><code class="name flex">
<span>def <span class="ident">sum</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Reduce the groups to the sum.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sum(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Reduce the groups to the sum.
    &#34;&#34;&#34;
    return wrap_df(self._df.groupby(self.by, self.selection, &#34;sum&#34;))</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pypolars.frame.GroupBy"><code class="flex name class">
<span>class <span class="ident">GroupBy</span></span>
<span>(</span><span>df: <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a>, by: List[str])</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GroupBy:
    def __init__(self, df: DataFrame, by: &#34;List[str]&#34;):
        self._df = df
        self.by = by

    def agg(
        self, column_to_agg: &#34;Union[List[Tuple[str, List[str]]], Dict[str, List[str]]]&#34;
    ) -&gt; DataFrame:
        &#34;&#34;&#34;
        Use multiple aggregations on columns

        Parameters
        ----------
        column_to_agg
            map column to aggregation functions

            Examples:
                [(&#34;foo&#34;, [&#34;sum&#34;, &#34;n_unique&#34;, &#34;min&#34;]),
                 (&#34;bar&#34;: [&#34;max&#34;])]

                {&#34;foo&#34;: [&#34;sum&#34;, &#34;n_unique&#34;, &#34;min&#34;],
                &#34;bar&#34;: &#34;max&#34; }

        Returns
        -------
        Result of groupby split apply operations.
        &#34;&#34;&#34;
        if isinstance(column_to_agg, dict):
            column_to_agg = [
                (column, [agg] if isinstance(agg, str) else agg)
                for (column, agg) in column_to_agg.items()
            ]
        else:
            column_to_agg = [
                (column, [agg] if isinstance(agg, str) else agg)
                for (column, agg) in column_to_agg
            ]

        return wrap_df(self._df.groupby_agg(self.by, column_to_agg))

    def select(self, columns: &#34;Union[str, List[str]]&#34;) -&gt; &#34;GBSelection&#34;:
        &#34;&#34;&#34;
        Select the columns that will be aggregated.

        Parameters
        ----------
        columns
            One or multiple columns
        &#34;&#34;&#34;
        if isinstance(columns, str):
            columns = [columns]
        return GBSelection(self._df, self.by, columns)

    def select_all(self):
        &#34;&#34;&#34;
        Select all columns for aggregation.
        &#34;&#34;&#34;
        return GBSelection(self._df, self.by, None)

    def pivot(self, pivot_column: str, values_column: str) -&gt; &#34;PivotOps&#34;:
        &#34;&#34;&#34;
        Do a pivot operation based on the group key, a pivot column and an aggregation function on the values column.

        Parameters
        ----------
        pivot_column
            Column to pivot.
        values_column
            Column that will be aggregated
        &#34;&#34;&#34;
        return PivotOps(self._df, self.by, pivot_column, values_column)

    def first(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Aggregate the first values in the group.
        &#34;&#34;&#34;
        return self.select_all().first()

    def last(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Aggregate the last values in the group.
        &#34;&#34;&#34;
        return self.select_all().last()

    def sum(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Reduce the groups to the sum.
        &#34;&#34;&#34;
        return self.select_all().sum()

    def min(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Reduce the groups to the minimal value.
        &#34;&#34;&#34;
        return self.select_all().min()

    def max(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Reduce the groups to the maximal value.
        &#34;&#34;&#34;
        return self.select_all().max()

    def count(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Count the number of values in each group.
        &#34;&#34;&#34;
        return self.select_all().count()

    def mean(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Reduce the groups to the mean values.
        &#34;&#34;&#34;
        return self.select_all().mean()

    def n_unique(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Count the unique values per group.
        &#34;&#34;&#34;
        return self.select_all().n_unique()

    def quantile(self, quantile: float) -&gt; DataFrame:
        &#34;&#34;&#34;
        Count the unique values per group.
        &#34;&#34;&#34;
        return self.select_all().quantile(quantile)

    def median(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Return the median per group.
        &#34;&#34;&#34;
        return self.select_all().median()

    def agg_list(self) -&gt; DataFrame:
        &#34;&#34;&#34;
        Aggregate the groups into Series.
        &#34;&#34;&#34;
        return self.select_all().agg_list()</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pypolars.frame.GroupBy.agg"><code class="name flex">
<span>def <span class="ident">agg</span></span>(<span>self, column_to_agg: Union[List[Tuple[str, List[str]]], Dict[str, List[str]]]) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Use multiple aggregations on columns</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>column_to_agg</code></strong></dt>
<dd>
<p>map column to aggregation functions</p>
<p>Examples:
[("foo", ["sum", "n_unique", "min"]),
("bar": ["max"])]</p>
<pre><code>{"foo": ["sum", "n_unique", "min"],
"bar": "max" }
</code></pre>
</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Result of groupby split apply operations.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def agg(
    self, column_to_agg: &#34;Union[List[Tuple[str, List[str]]], Dict[str, List[str]]]&#34;
) -&gt; DataFrame:
    &#34;&#34;&#34;
    Use multiple aggregations on columns

    Parameters
    ----------
    column_to_agg
        map column to aggregation functions

        Examples:
            [(&#34;foo&#34;, [&#34;sum&#34;, &#34;n_unique&#34;, &#34;min&#34;]),
             (&#34;bar&#34;: [&#34;max&#34;])]

            {&#34;foo&#34;: [&#34;sum&#34;, &#34;n_unique&#34;, &#34;min&#34;],
            &#34;bar&#34;: &#34;max&#34; }

    Returns
    -------
    Result of groupby split apply operations.
    &#34;&#34;&#34;
    if isinstance(column_to_agg, dict):
        column_to_agg = [
            (column, [agg] if isinstance(agg, str) else agg)
            for (column, agg) in column_to_agg.items()
        ]
    else:
        column_to_agg = [
            (column, [agg] if isinstance(agg, str) else agg)
            for (column, agg) in column_to_agg
        ]

    return wrap_df(self._df.groupby_agg(self.by, column_to_agg))</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GroupBy.agg_list"><code class="name flex">
<span>def <span class="ident">agg_list</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate the groups into Series.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def agg_list(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Aggregate the groups into Series.
    &#34;&#34;&#34;
    return self.select_all().agg_list()</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GroupBy.count"><code class="name flex">
<span>def <span class="ident">count</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Count the number of values in each group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def count(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Count the number of values in each group.
    &#34;&#34;&#34;
    return self.select_all().count()</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GroupBy.first"><code class="name flex">
<span>def <span class="ident">first</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate the first values in the group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def first(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Aggregate the first values in the group.
    &#34;&#34;&#34;
    return self.select_all().first()</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GroupBy.last"><code class="name flex">
<span>def <span class="ident">last</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Aggregate the last values in the group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def last(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Aggregate the last values in the group.
    &#34;&#34;&#34;
    return self.select_all().last()</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GroupBy.max"><code class="name flex">
<span>def <span class="ident">max</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Reduce the groups to the maximal value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def max(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Reduce the groups to the maximal value.
    &#34;&#34;&#34;
    return self.select_all().max()</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GroupBy.mean"><code class="name flex">
<span>def <span class="ident">mean</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Reduce the groups to the mean values.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mean(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Reduce the groups to the mean values.
    &#34;&#34;&#34;
    return self.select_all().mean()</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GroupBy.median"><code class="name flex">
<span>def <span class="ident">median</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Return the median per group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def median(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Return the median per group.
    &#34;&#34;&#34;
    return self.select_all().median()</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GroupBy.min"><code class="name flex">
<span>def <span class="ident">min</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Reduce the groups to the minimal value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def min(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Reduce the groups to the minimal value.
    &#34;&#34;&#34;
    return self.select_all().min()</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GroupBy.n_unique"><code class="name flex">
<span>def <span class="ident">n_unique</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Count the unique values per group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def n_unique(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Count the unique values per group.
    &#34;&#34;&#34;
    return self.select_all().n_unique()</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GroupBy.pivot"><code class="name flex">
<span>def <span class="ident">pivot</span></span>(<span>self, pivot_column: str, values_column: str) ‑> <a title="pypolars.frame.PivotOps" href="#pypolars.frame.PivotOps">PivotOps</a></span>
</code></dt>
<dd>
<div class="desc"><p>Do a pivot operation based on the group key, a pivot column and an aggregation function on the values column.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>pivot_column</code></strong></dt>
<dd>Column to pivot.</dd>
<dt><strong><code>values_column</code></strong></dt>
<dd>Column that will be aggregated</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pivot(self, pivot_column: str, values_column: str) -&gt; &#34;PivotOps&#34;:
    &#34;&#34;&#34;
    Do a pivot operation based on the group key, a pivot column and an aggregation function on the values column.

    Parameters
    ----------
    pivot_column
        Column to pivot.
    values_column
        Column that will be aggregated
    &#34;&#34;&#34;
    return PivotOps(self._df, self.by, pivot_column, values_column)</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GroupBy.quantile"><code class="name flex">
<span>def <span class="ident">quantile</span></span>(<span>self, quantile: float) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Count the unique values per group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def quantile(self, quantile: float) -&gt; DataFrame:
    &#34;&#34;&#34;
    Count the unique values per group.
    &#34;&#34;&#34;
    return self.select_all().quantile(quantile)</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GroupBy.select"><code class="name flex">
<span>def <span class="ident">select</span></span>(<span>self, columns: Union[str, List[str]]) ‑> <a title="pypolars.frame.GBSelection" href="#pypolars.frame.GBSelection">GBSelection</a></span>
</code></dt>
<dd>
<div class="desc"><p>Select the columns that will be aggregated.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>columns</code></strong></dt>
<dd>One or multiple columns</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def select(self, columns: &#34;Union[str, List[str]]&#34;) -&gt; &#34;GBSelection&#34;:
    &#34;&#34;&#34;
    Select the columns that will be aggregated.

    Parameters
    ----------
    columns
        One or multiple columns
    &#34;&#34;&#34;
    if isinstance(columns, str):
        columns = [columns]
    return GBSelection(self._df, self.by, columns)</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GroupBy.select_all"><code class="name flex">
<span>def <span class="ident">select_all</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Select all columns for aggregation.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def select_all(self):
    &#34;&#34;&#34;
    Select all columns for aggregation.
    &#34;&#34;&#34;
    return GBSelection(self._df, self.by, None)</code></pre>
</details>
</dd>
<dt id="pypolars.frame.GroupBy.sum"><code class="name flex">
<span>def <span class="ident">sum</span></span>(<span>self) ‑> <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></span>
</code></dt>
<dd>
<div class="desc"><p>Reduce the groups to the sum.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sum(self) -&gt; DataFrame:
    &#34;&#34;&#34;
    Reduce the groups to the sum.
    &#34;&#34;&#34;
    return self.select_all().sum()</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pypolars.frame.PivotOps"><code class="flex name class">
<span>class <span class="ident">PivotOps</span></span>
<span>(</span><span>df: <a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a>, by: List[str], pivot_column: str, values_column: str)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PivotOps:
    def __init__(
        self, df: DataFrame, by: &#34;List[str]&#34;, pivot_column: str, values_column: str
    ):
        self._df = df
        self.by = by
        self.pivot_column = pivot_column
        self.values_column = values_column

    def first(self):
        &#34;&#34;&#34;
        Get the first value per group.
        &#34;&#34;&#34;
        return wrap_df(
            self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;first&#34;)
        )

    def sum(self):
        &#34;&#34;&#34;
        Get the sum per group.
        &#34;&#34;&#34;
        return wrap_df(
            self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;sum&#34;)
        )

    def min(self):
        &#34;&#34;&#34;
        Get the minimal value per group.
        &#34;&#34;&#34;
        return wrap_df(
            self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;min&#34;)
        )

    def max(self):
        &#34;&#34;&#34;
        Get the maximal value per group.
        &#34;&#34;&#34;
        return wrap_df(
            self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;max&#34;)
        )

    def mean(self):
        &#34;&#34;&#34;
        Get the mean value per group.
        &#34;&#34;&#34;
        return wrap_df(
            self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;mean&#34;)
        )

    def count(self):
        &#34;&#34;&#34;
        Count the values per group.
        &#34;&#34;&#34;
        return wrap_df(
            self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;count&#34;)
        )

    def median(self):
        &#34;&#34;&#34;
        Get the median value per group.
        &#34;&#34;&#34;
        return wrap_df(
            self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;median&#34;)
        )</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pypolars.frame.PivotOps.count"><code class="name flex">
<span>def <span class="ident">count</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Count the values per group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def count(self):
    &#34;&#34;&#34;
    Count the values per group.
    &#34;&#34;&#34;
    return wrap_df(
        self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;count&#34;)
    )</code></pre>
</details>
</dd>
<dt id="pypolars.frame.PivotOps.first"><code class="name flex">
<span>def <span class="ident">first</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the first value per group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def first(self):
    &#34;&#34;&#34;
    Get the first value per group.
    &#34;&#34;&#34;
    return wrap_df(
        self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;first&#34;)
    )</code></pre>
</details>
</dd>
<dt id="pypolars.frame.PivotOps.max"><code class="name flex">
<span>def <span class="ident">max</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the maximal value per group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def max(self):
    &#34;&#34;&#34;
    Get the maximal value per group.
    &#34;&#34;&#34;
    return wrap_df(
        self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;max&#34;)
    )</code></pre>
</details>
</dd>
<dt id="pypolars.frame.PivotOps.mean"><code class="name flex">
<span>def <span class="ident">mean</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the mean value per group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mean(self):
    &#34;&#34;&#34;
    Get the mean value per group.
    &#34;&#34;&#34;
    return wrap_df(
        self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;mean&#34;)
    )</code></pre>
</details>
</dd>
<dt id="pypolars.frame.PivotOps.median"><code class="name flex">
<span>def <span class="ident">median</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the median value per group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def median(self):
    &#34;&#34;&#34;
    Get the median value per group.
    &#34;&#34;&#34;
    return wrap_df(
        self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;median&#34;)
    )</code></pre>
</details>
</dd>
<dt id="pypolars.frame.PivotOps.min"><code class="name flex">
<span>def <span class="ident">min</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the minimal value per group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def min(self):
    &#34;&#34;&#34;
    Get the minimal value per group.
    &#34;&#34;&#34;
    return wrap_df(
        self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;min&#34;)
    )</code></pre>
</details>
</dd>
<dt id="pypolars.frame.PivotOps.sum"><code class="name flex">
<span>def <span class="ident">sum</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Get the sum per group.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sum(self):
    &#34;&#34;&#34;
    Get the sum per group.
    &#34;&#34;&#34;
    return wrap_df(
        self._df.pivot(self.by, self.pivot_column, self.values_column, &#34;sum&#34;)
    )</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pypolars" href="index.html">pypolars</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pypolars.frame.prepare_other" href="#pypolars.frame.prepare_other">prepare_other</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pypolars.frame.DataFrame" href="#pypolars.frame.DataFrame">DataFrame</a></code></h4>
<ul class="two-column">
<li><code><a title="pypolars.frame.DataFrame.clone" href="#pypolars.frame.DataFrame.clone">clone</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.columns" href="#pypolars.frame.DataFrame.columns">columns</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.drop" href="#pypolars.frame.DataFrame.drop">drop</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.drop_duplicates" href="#pypolars.frame.DataFrame.drop_duplicates">drop_duplicates</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.drop_in_place" href="#pypolars.frame.DataFrame.drop_in_place">drop_in_place</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.drop_nulls" href="#pypolars.frame.DataFrame.drop_nulls">drop_nulls</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.dtypes" href="#pypolars.frame.DataFrame.dtypes">dtypes</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.explode" href="#pypolars.frame.DataFrame.explode">explode</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.fill_none" href="#pypolars.frame.DataFrame.fill_none">fill_none</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.frame_equal" href="#pypolars.frame.DataFrame.frame_equal">frame_equal</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.get_columns" href="#pypolars.frame.DataFrame.get_columns">get_columns</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.groupby" href="#pypolars.frame.DataFrame.groupby">groupby</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.head" href="#pypolars.frame.DataFrame.head">head</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.height" href="#pypolars.frame.DataFrame.height">height</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.hstack" href="#pypolars.frame.DataFrame.hstack">hstack</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.insert_at_idx" href="#pypolars.frame.DataFrame.insert_at_idx">insert_at_idx</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.is_duplicated" href="#pypolars.frame.DataFrame.is_duplicated">is_duplicated</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.is_unique" href="#pypolars.frame.DataFrame.is_unique">is_unique</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.join" href="#pypolars.frame.DataFrame.join">join</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.lazy" href="#pypolars.frame.DataFrame.lazy">lazy</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.max" href="#pypolars.frame.DataFrame.max">max</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.mean" href="#pypolars.frame.DataFrame.mean">mean</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.median" href="#pypolars.frame.DataFrame.median">median</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.melt" href="#pypolars.frame.DataFrame.melt">melt</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.min" href="#pypolars.frame.DataFrame.min">min</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.n_chunks" href="#pypolars.frame.DataFrame.n_chunks">n_chunks</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.pipe" href="#pypolars.frame.DataFrame.pipe">pipe</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.quantile" href="#pypolars.frame.DataFrame.quantile">quantile</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.read_csv" href="#pypolars.frame.DataFrame.read_csv">read_csv</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.read_ipc" href="#pypolars.frame.DataFrame.read_ipc">read_ipc</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.read_parquet" href="#pypolars.frame.DataFrame.read_parquet">read_parquet</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.replace" href="#pypolars.frame.DataFrame.replace">replace</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.replace_at_idx" href="#pypolars.frame.DataFrame.replace_at_idx">replace_at_idx</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.select_at_idx" href="#pypolars.frame.DataFrame.select_at_idx">select_at_idx</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.shape" href="#pypolars.frame.DataFrame.shape">shape</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.shift" href="#pypolars.frame.DataFrame.shift">shift</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.slice" href="#pypolars.frame.DataFrame.slice">slice</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.sort" href="#pypolars.frame.DataFrame.sort">sort</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.std" href="#pypolars.frame.DataFrame.std">std</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.sum" href="#pypolars.frame.DataFrame.sum">sum</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.tail" href="#pypolars.frame.DataFrame.tail">tail</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.to_csv" href="#pypolars.frame.DataFrame.to_csv">to_csv</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.to_dummies" href="#pypolars.frame.DataFrame.to_dummies">to_dummies</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.to_ipc" href="#pypolars.frame.DataFrame.to_ipc">to_ipc</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.to_numpy" href="#pypolars.frame.DataFrame.to_numpy">to_numpy</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.to_pandas" href="#pypolars.frame.DataFrame.to_pandas">to_pandas</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.var" href="#pypolars.frame.DataFrame.var">var</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.vstack" href="#pypolars.frame.DataFrame.vstack">vstack</a></code></li>
<li><code><a title="pypolars.frame.DataFrame.width" href="#pypolars.frame.DataFrame.width">width</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pypolars.frame.GBSelection" href="#pypolars.frame.GBSelection">GBSelection</a></code></h4>
<ul class="two-column">
<li><code><a title="pypolars.frame.GBSelection.agg_list" href="#pypolars.frame.GBSelection.agg_list">agg_list</a></code></li>
<li><code><a title="pypolars.frame.GBSelection.count" href="#pypolars.frame.GBSelection.count">count</a></code></li>
<li><code><a title="pypolars.frame.GBSelection.first" href="#pypolars.frame.GBSelection.first">first</a></code></li>
<li><code><a title="pypolars.frame.GBSelection.last" href="#pypolars.frame.GBSelection.last">last</a></code></li>
<li><code><a title="pypolars.frame.GBSelection.max" href="#pypolars.frame.GBSelection.max">max</a></code></li>
<li><code><a title="pypolars.frame.GBSelection.mean" href="#pypolars.frame.GBSelection.mean">mean</a></code></li>
<li><code><a title="pypolars.frame.GBSelection.median" href="#pypolars.frame.GBSelection.median">median</a></code></li>
<li><code><a title="pypolars.frame.GBSelection.min" href="#pypolars.frame.GBSelection.min">min</a></code></li>
<li><code><a title="pypolars.frame.GBSelection.n_unique" href="#pypolars.frame.GBSelection.n_unique">n_unique</a></code></li>
<li><code><a title="pypolars.frame.GBSelection.quantile" href="#pypolars.frame.GBSelection.quantile">quantile</a></code></li>
<li><code><a title="pypolars.frame.GBSelection.sum" href="#pypolars.frame.GBSelection.sum">sum</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pypolars.frame.GroupBy" href="#pypolars.frame.GroupBy">GroupBy</a></code></h4>
<ul class="two-column">
<li><code><a title="pypolars.frame.GroupBy.agg" href="#pypolars.frame.GroupBy.agg">agg</a></code></li>
<li><code><a title="pypolars.frame.GroupBy.agg_list" href="#pypolars.frame.GroupBy.agg_list">agg_list</a></code></li>
<li><code><a title="pypolars.frame.GroupBy.count" href="#pypolars.frame.GroupBy.count">count</a></code></li>
<li><code><a title="pypolars.frame.GroupBy.first" href="#pypolars.frame.GroupBy.first">first</a></code></li>
<li><code><a title="pypolars.frame.GroupBy.last" href="#pypolars.frame.GroupBy.last">last</a></code></li>
<li><code><a title="pypolars.frame.GroupBy.max" href="#pypolars.frame.GroupBy.max">max</a></code></li>
<li><code><a title="pypolars.frame.GroupBy.mean" href="#pypolars.frame.GroupBy.mean">mean</a></code></li>
<li><code><a title="pypolars.frame.GroupBy.median" href="#pypolars.frame.GroupBy.median">median</a></code></li>
<li><code><a title="pypolars.frame.GroupBy.min" href="#pypolars.frame.GroupBy.min">min</a></code></li>
<li><code><a title="pypolars.frame.GroupBy.n_unique" href="#pypolars.frame.GroupBy.n_unique">n_unique</a></code></li>
<li><code><a title="pypolars.frame.GroupBy.pivot" href="#pypolars.frame.GroupBy.pivot">pivot</a></code></li>
<li><code><a title="pypolars.frame.GroupBy.quantile" href="#pypolars.frame.GroupBy.quantile">quantile</a></code></li>
<li><code><a title="pypolars.frame.GroupBy.select" href="#pypolars.frame.GroupBy.select">select</a></code></li>
<li><code><a title="pypolars.frame.GroupBy.select_all" href="#pypolars.frame.GroupBy.select_all">select_all</a></code></li>
<li><code><a title="pypolars.frame.GroupBy.sum" href="#pypolars.frame.GroupBy.sum">sum</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pypolars.frame.PivotOps" href="#pypolars.frame.PivotOps">PivotOps</a></code></h4>
<ul class="two-column">
<li><code><a title="pypolars.frame.PivotOps.count" href="#pypolars.frame.PivotOps.count">count</a></code></li>
<li><code><a title="pypolars.frame.PivotOps.first" href="#pypolars.frame.PivotOps.first">first</a></code></li>
<li><code><a title="pypolars.frame.PivotOps.max" href="#pypolars.frame.PivotOps.max">max</a></code></li>
<li><code><a title="pypolars.frame.PivotOps.mean" href="#pypolars.frame.PivotOps.mean">mean</a></code></li>
<li><code><a title="pypolars.frame.PivotOps.median" href="#pypolars.frame.PivotOps.median">median</a></code></li>
<li><code><a title="pypolars.frame.PivotOps.min" href="#pypolars.frame.PivotOps.min">min</a></code></li>
<li><code><a title="pypolars.frame.PivotOps.sum" href="#pypolars.frame.PivotOps.sum">sum</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>